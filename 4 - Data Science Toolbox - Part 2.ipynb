{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Toolbox - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterators\n",
    "\n",
    "List, strings, dictionaries, file connections, etc are all iterables. That is, they are objects with an associated iter() method. Which means we can iterate through them using a for loop for instance. \n",
    "We can create an iterator using the **iter()** function, and then call the **next()** function to iterate through the iterator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay garrick\n",
      "barry allen\n",
      "wally west\n",
      "bart allen\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: flash\n",
    "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "\n",
    "# Print each list item in flash using a for loop\n",
    "for item in flash:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay garrick\n",
      "barry allen\n",
      "wally west\n",
      "bart allen\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator for flash: superspeed\n",
    "superspeed = iter(flash)\n",
    "\n",
    "# Print each item from the iterator\n",
    "print(next(superspeed))\n",
    "print(next(superspeed))\n",
    "print(next(superspeed))\n",
    "print(next(superspeed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with iterators\n",
    "\n",
    "**Enumerate:** takes any iterable as an argument and return a special enumerate object, which contains the key-value pair with the index and the value of that item as tuples.\n",
    "**Zip:** Receive an arbitrary number of iterables and create an iterator of tuples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'charles xavier'), (1, 'bobby drake'), (2, 'kurt wagner'), (3, 'max eisenhardt'), (4, 'kitty pryde')]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: mutants\n",
    "mutants = ['charles xavier', \n",
    "            'bobby drake', \n",
    "            'kurt wagner', \n",
    "            'max eisenhardt', \n",
    "            'kitty pryde']\n",
    "\n",
    "# Create a list of tuples: mutant_list\n",
    "mutant_list = list(enumerate(mutants))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(mutant_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 charles xavier\n",
      "1 bobby drake\n",
      "2 kurt wagner\n",
      "3 max eisenhardt\n",
      "4 kitty pryde\n"
     ]
    }
   ],
   "source": [
    "# Unpack and print the tuple pairs\n",
    "for index1, value1 in enumerate(mutants):\n",
    "    print(index1, value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 charles xavier\n",
      "2 bobby drake\n",
      "3 kurt wagner\n",
      "4 max eisenhardt\n",
      "5 kitty pryde\n"
     ]
    }
   ],
   "source": [
    "# Change the start index\n",
    "for index2, value2 in enumerate(mutants, start = 1):\n",
    "    print(index2, value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data in chunks into memory\n",
    "\n",
    "If we're loading too much data that won't fit into memory we can use iterator to load data in chunks. read_csv function from Pandas does that by using the chunksize parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example won't work as the file does not exist\n",
    "\n",
    "import pandas as pd\n",
    "# Initialize variable to store the data\n",
    "result = [] \n",
    "\n",
    "for chunk in pd.read_csv('data.csv', chunksize=1000):\n",
    "    # Chunk is an iterable and each iteration is a dataframe\n",
    "    # As an example we are summing up a column x for each chunk an storing in a list (silly example, we could just use an int variable and += sum(chunk['x']))\n",
    "    result.append(sum(chunk['x']))\n",
    "# Add ups all chunks of data\n",
    "total = sum(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators\n",
    "\n",
    "It's exactly the same as the list comprehension, with the exception that it does not store the list in memory, instead it produces the data as required.\n",
    "It can help when working with extremely large sequences. The only difference when building them is the change from [] to () in the definition. \n",
    "We can also create generator functions. They are defined with the **def** keyworks and the only difference between a regular function is that instead of using **return** to return a value, we use the keyword **yield**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# Create generator object: result\n",
    "result = (num for num in range(31))\n",
    "\n",
    "# Print the first 5 values\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "print(next(result))\n",
    "\n",
    "# Print the rest of the values\n",
    "for value in result:\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings\n",
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "# Define generator function get_lengths\n",
    "def get_lengths(input_list):\n",
    "    \"\"\"Generator function that yields the\n",
    "    length of the strings in input_list.\"\"\"\n",
    "\n",
    "    # Yield the length of a string\n",
    "    for person in input_list:\n",
    "        yield len(person)\n",
    "\n",
    "# Print the values generated by get_lengths()\n",
    "for value in get_lengths(lannister):\n",
    "    print(value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
